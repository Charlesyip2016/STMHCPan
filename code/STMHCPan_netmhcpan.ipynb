{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_sequence = pd.read_csv('../data/other/HLAI_pseudosequences_34mer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data):\n",
    "    pep_inputs, hla_inputs, labels = [], [], []\n",
    "    pep_lens = []\n",
    "    for pep, hla, label in zip(data.peptide, data.HLA_sequence, data.label):\n",
    "#         pep_lens.append(len(pep)+34)\n",
    "        pep_lens.append(49)\n",
    "        pep, hla = pep.ljust(pep_max_len, '-'), hla.ljust(hla_max_len, '-')\n",
    "        pep_input = [[vocab[n] for n in pep]] # [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]\n",
    "        hla_input = [[vocab[n] for n in hla]]\n",
    "        pep_inputs.extend(pep_input)\n",
    "        hla_inputs.extend(hla_input)\n",
    "        labels.append(label)\n",
    "    return torch.LongTensor(pep_inputs), torch.LongTensor(hla_inputs), torch.LongTensor(labels), torch.LongTensor(pep_lens)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, pep_inputs, hla_inputs, labels, pep_lens):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.pep_inputs = pep_inputs\n",
    "        self.hla_inputs = hla_inputs\n",
    "        self.labels = labels\n",
    "        self.pep_lens = pep_lens\n",
    "\n",
    "    def __len__(self): # 样本数\n",
    "        return self.pep_inputs.shape[0] # 改成hla_inputs也可以哦！\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         return self.pep_inputs[idx], self.hla_inputs[idx], self.labels[idx],self.pep_lens[idx]\n",
    "        return torch.cat((self.hla_inputs[idx],self.pep_inputs[idx]), dim=0), self.labels[idx], self.pep_lens[idx]\n",
    "\n",
    "def seq_len_to_mask(seq_len, max_len=49): #50\n",
    "    r\"\"\"\n",
    "    将一个表示sequence length的一维数组转换为二维的mask，不包含的位置为0。\n",
    "    转变 1-d seq_len到2-d mask.\n",
    "    .. code-block::\n",
    "    \n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.size())\n",
    "        torch.Size([14, 15])\n",
    "        >>> seq_len = np.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.shape)\n",
    "        (14, 15)\n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len, max_len=100)\n",
    "        >>>print(mask.size())\n",
    "        torch.Size([14, 100])\n",
    "    :param np.ndarray,torch.LongTensor seq_len: shape将是(B,)\n",
    "    :param int max_len: 将长度pad到这个长度。默认(None)使用的是seq_len中最长的长度。但在nn.DataParallel的场景下可能不同卡的seq_len会有\n",
    "        区别，所以需要传入一个max_len使得mask的长度是pad到该长度。\n",
    "    :return: np.ndarray, torch.Tensor 。shape将是(B, max_length)， 元素类似为bool或torch.uint8\n",
    "    \"\"\"\n",
    "    if isinstance(seq_len, np.ndarray):\n",
    "        assert len(np.shape(seq_len)) == 1, f\"seq_len can only have one dimension, got {len(np.shape(seq_len))}.\"\n",
    "        max_len = int(max_len) if max_len else int(seq_len.max())\n",
    "        broad_cast_seq_len = np.tile(np.arange(max_len), (len(seq_len), 1))\n",
    "        mask = broad_cast_seq_len < seq_len.reshape(-1, 1)\n",
    "\n",
    "    elif isinstance(seq_len, torch.Tensor):\n",
    "        assert seq_len.dim() == 1, f\"seq_len can only have one dimension, got {seq_len.dim() == 1}.\"\n",
    "        batch_size = seq_len.size(0)\n",
    "        max_len = int(max_len) if max_len else seq_len.max().long()\n",
    "        broad_cast_seq_len = torch.arange(max_len).expand(batch_size, -1).to(seq_len)\n",
    "        mask = broad_cast_seq_len.lt(seq_len.unsqueeze(1))\n",
    "    else:\n",
    "        raise TypeError(\"Only support 1-d numpy.ndarray or 1-d torch.Tensor.\")\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_embeddings(init_embed, padding_idx=None):\n",
    "    r\"\"\"\n",
    "    根据输入的init_embed返回Embedding对象。如果输入是tuple, 则随机初始化一个nn.Embedding; 如果输入是numpy.ndarray, 则按照ndarray\n",
    "    的值将nn.Embedding初始化; 如果输入是torch.Tensor, 则按该值初始化nn.Embedding; 如果输入是fastNLP中的embedding将不做处理\n",
    "    返回原对象。\n",
    "    :param init_embed: 可以是 tuple:(num_embedings, embedding_dim), 即embedding的大小和每个词的维度;也可以传入\n",
    "        nn.Embedding 对象, 此时就以传入的对象作为embedding; 传入np.ndarray也行，将使用传入的ndarray作为作为Embedding初始化;\n",
    "        传入torch.Tensor, 将使用传入的值作为Embedding初始化。\n",
    "    :param padding_idx: 当传入tuple时，padding_idx有效\n",
    "    :return nn.Embedding:  embeddings\n",
    "    \"\"\"\n",
    "    if isinstance(init_embed, tuple):\n",
    "        res = nn.Embedding(num_embeddings=init_embed[0], embedding_dim=init_embed[1], padding_idx=padding_idx)\n",
    "#         nn.init.uniform_(res.weight.data, a=-np.sqrt(3 / res.weight.data.size(1)),\n",
    "#                          b=np.sqrt(3 / res.weight.data.size(1)))\n",
    "    elif isinstance(init_embed, nn.Module):\n",
    "        res = init_embed\n",
    "    elif isinstance(init_embed, torch.Tensor):\n",
    "        res = nn.Embedding.from_pretrained(init_embed, freeze=False)\n",
    "    elif isinstance(init_embed, np.ndarray):\n",
    "        init_embed = torch.tensor(init_embed, dtype=torch.float32)\n",
    "        res = nn.Embedding.from_pretrained(init_embed, freeze=False)\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'invalid init_embed type: {}'.format((type(init_embed))))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StarTransformer(nn.Module):\n",
    "    r\"\"\"\n",
    "    Star-Transformer 的encoder部分。 输入3d的文本输入, 返回相同长度的文本编码\n",
    "    paper: https://arxiv.org/abs/1902.09113\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers, num_head, head_dim, dropout=0.1, max_len=None):\n",
    "        r\"\"\"\n",
    "        \n",
    "        :param int hidden_size: 输入维度的大小。同时也是输出维度的大小。\n",
    "        :param int num_layers: star-transformer的层数\n",
    "        :param int num_head: head的数量。\n",
    "        :param int head_dim: 每个head的维度大小。\n",
    "        :param float dropout: dropout 概率. Default: 0.1\n",
    "        :param int max_len: int or None, 如果为int，输入序列的最大长度，\n",
    "            模型会为输入序列加上position embedding。\n",
    "            若为`None`，忽略加上position embedding的步骤. Default: `None`\n",
    "        \"\"\"\n",
    "        super(StarTransformer, self).__init__()\n",
    "        self.iters = num_layers\n",
    "\n",
    "        self.norm = nn.ModuleList([nn.LayerNorm(hidden_size, eps=1e-6) for _ in range(self.iters)])\n",
    "        # self.emb_fc = nn.Conv2d(hidden_size, hidden_size, 1)\n",
    "        self.emb_drop = nn.Dropout(dropout)\n",
    "        self.ring_att = nn.ModuleList(\n",
    "            [_MSA1(hidden_size, nhead=num_head, head_dim=head_dim, dropout=0.0)\n",
    "             for _ in range(self.iters)])\n",
    "        self.star_att = nn.ModuleList(\n",
    "            [_MSA2(hidden_size, nhead=num_head, head_dim=head_dim, dropout=0.0)\n",
    "             for _ in range(self.iters)])\n",
    "\n",
    "        if max_len is not None:\n",
    "            self.pos_emb = nn.Embedding(max_len, hidden_size)\n",
    "        else:\n",
    "            self.pos_emb = None\n",
    "\n",
    "    def forward(self, data, mask):\n",
    "        r\"\"\"\n",
    "        :param FloatTensor data: [batch, length, hidden] 输入的序列\n",
    "        :param ByteTensor mask: [batch, length] 输入序列的padding mask, 在没有内容(padding 部分) 为 0,\n",
    "            否则为 1\n",
    "        :return: [batch, length, hidden] 编码后的输出序列\n",
    "                [batch, hidden] 全局 relay 节点, 详见论文\n",
    "        \"\"\"\n",
    "\n",
    "        def norm_func(f, x):\n",
    "            # B, H, L, 1\n",
    "            return f(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "\n",
    "        B, L, H = data.size()\n",
    "        mask = (mask.eq(False))  # flip the mask for masked_fill_\n",
    "        smask = torch.cat([torch.zeros(B, 1, ).byte().to(mask), mask], 1)\n",
    "\n",
    "        embs = data.permute(0, 2, 1)[:, :, :, None]  # B H L 1\n",
    "        if self.pos_emb:\n",
    "            P = self.pos_emb(torch.arange(L, dtype=torch.long, device=embs.device) \\\n",
    "                             .view(1, L)).permute(0, 2, 1).contiguous()[:, :, :, None]  # 1 H L 1\n",
    "            embs = embs + P\n",
    "        embs = norm_func(self.emb_drop, embs)\n",
    "        nodes = embs\n",
    "        relay = embs.mean(2, keepdim=True)\n",
    "        ex_mask = mask[:, None, :, None].expand(B, H, L, 1)\n",
    "        r_embs = embs.view(B, H, 1, L)\n",
    "#         nodes_attns = []\n",
    "#         relays_attns = []\n",
    "        for i in range(self.iters):\n",
    "            ax = torch.cat([r_embs, relay.expand(B, H, 1, L)], 2)\n",
    "            nodes = F.leaky_relu(self.ring_att[i](norm_func(self.norm[i], nodes), ax=ax))\n",
    "            # nodes = F.leaky_relu(self.ring_att[i](nodes, ax=ax))\n",
    "#             nodes_attns.append(nodes_att)\n",
    "            relay = F.leaky_relu(self.star_att[i](relay, torch.cat([relay, nodes], 2), smask))\n",
    "#             relays_attns.append(relay_att)\n",
    "            nodes = nodes.masked_fill_(ex_mask, 0)\n",
    "\n",
    "        nodes = nodes.view(B, H, L).permute(0, 2, 1)\n",
    "\n",
    "        return nodes, relay.view(B, H)#, nodes_attns, relays_attns\n",
    "\n",
    "\n",
    "class _MSA1(nn.Module):\n",
    "    def __init__(self, nhid, nhead=10, head_dim=10, dropout=0.1):\n",
    "        super(_MSA1, self).__init__()\n",
    "        # Multi-head Self Attention Case 1, doing self-attention for small regions\n",
    "        # Due to the architecture of GPU, using hadamard production and summation are faster than dot production when unfold_size is very small\n",
    "        self.WQ = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WK = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WV = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WO = nn.Conv2d(nhead * head_dim, nhid, 1)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.nhid, self.nhead, self.head_dim, self.unfold_size = nhid, nhead, head_dim, 3\n",
    "\n",
    "    def forward(self, x, ax=None):\n",
    "        # x: B, H, L, 1, ax : B, H, X, L append features\n",
    "        nhid, nhead, head_dim, unfold_size = self.nhid, self.nhead, self.head_dim, self.unfold_size\n",
    "        B, H, L, _ = x.shape\n",
    "\n",
    "        q, k, v = self.WQ(x), self.WK(x), self.WV(x)  # x: (B,H,L,1)\n",
    "\n",
    "        if ax is not None:\n",
    "            aL = ax.shape[2]\n",
    "            ak = self.WK(ax).view(B, nhead, head_dim, aL, L)\n",
    "            av = self.WV(ax).view(B, nhead, head_dim, aL, L)\n",
    "        q = q.view(B, nhead, head_dim, 1, L)\n",
    "        k = F.unfold(k.view(B, nhead * head_dim, L, 1), (unfold_size, 1), padding=(unfold_size // 2, 0)) \\\n",
    "            .view(B, nhead, head_dim, unfold_size, L)\n",
    "        v = F.unfold(v.view(B, nhead * head_dim, L, 1), (unfold_size, 1), padding=(unfold_size // 2, 0)) \\\n",
    "            .view(B, nhead, head_dim, unfold_size, L)\n",
    "        if ax is not None:\n",
    "            k = torch.cat([k, ak], 3)\n",
    "            v = torch.cat([v, av], 3)\n",
    "\n",
    "        alphas = self.drop(F.softmax((q * k).sum(2, keepdim=True) / np.sqrt(head_dim), 3))  # B N L 1 U\n",
    "        att = (alphas * v).sum(3).view(B, nhead * head_dim, L, 1)\n",
    "\n",
    "        ret = self.WO(att)\n",
    "\n",
    "        return ret #,alphas\n",
    "\n",
    "\n",
    "class _MSA2(nn.Module):\n",
    "    def __init__(self, nhid, nhead=10, head_dim=10, dropout=0.1):\n",
    "        # Multi-head Self Attention Case 2, a broadcastable query for a sequence key and value\n",
    "        super(_MSA2, self).__init__()\n",
    "        self.WQ = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WK = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WV = nn.Conv2d(nhid, nhead * head_dim, 1)\n",
    "        self.WO = nn.Conv2d(nhead * head_dim, nhid, 1)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.nhid, self.nhead, self.head_dim, self.unfold_size = nhid, nhead, head_dim, 3\n",
    "    def forward(self, x, y, mask=None):\n",
    "        # x: B, H, 1, 1, 1 y: B H L 1\n",
    "        nhid, nhead, head_dim, unfold_size = self.nhid, self.nhead, self.head_dim, self.unfold_size\n",
    "        B, H, L, _ = y.shape\n",
    "\n",
    "        q, k, v = self.WQ(x), self.WK(y), self.WV(y)\n",
    "\n",
    "        q = q.view(B, nhead, 1, head_dim)  # B, H, 1, 1 -> B, N, 1, h\n",
    "        k = k.view(B, nhead, head_dim, L)  # B, H, L, 1 -> B, N, h, L\n",
    "        v = v.view(B, nhead, head_dim, L).permute(0, 1, 3, 2)  # B, H, L, 1 -> B, N, L, h\n",
    "        pre_a = torch.matmul(q, k) / np.sqrt(head_dim)\n",
    "        if mask is not None:\n",
    "            pre_a = pre_a.masked_fill(mask[:, None, None, :], -float('inf'))\n",
    "        alphas = self.drop(F.softmax(pre_a, 3))  # B, N, 1, L\n",
    "        att = torch.matmul(alphas, v).view(B, -1, 1, 1)  # B, N, 1, h -> B, N*h, 1, 1\n",
    "        return self.WO(att) #,alphas\n",
    "    \n",
    "class StarTransEnc(nn.Module):\n",
    "    r\"\"\"\n",
    "    带word embedding的Star-Transformer Encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 num_head,\n",
    "                 head_dim,\n",
    "                 max_len,\n",
    "                 emb_dropout,\n",
    "                 dropout):\n",
    "        r\"\"\"\n",
    "        \n",
    "        :param embed: 单词词典, 可以是 tuple, 包括(num_embedings, embedding_dim), 即\n",
    "            embedding的大小和每个词的维度. 也可以传入 nn.Embedding 对象,此时就以传入的对象作为embedding\n",
    "        :param hidden_size: 模型中特征维度.\n",
    "        :param num_layers: 模型层数.\n",
    "        :param num_head: 模型中multi-head的head个数.\n",
    "        :param head_dim: 模型中multi-head中每个head特征维度.\n",
    "        :param max_len: 模型能接受的最大输入长度.\n",
    "        :param emb_dropout: 词嵌入的dropout概率.\n",
    "        :param dropout: 模型除词嵌入外的dropout概率.\n",
    "        \"\"\"\n",
    "        super(StarTransEnc, self).__init__()\n",
    "        self.embedding = get_embeddings(embed,padding_idx=0)\n",
    "        emb_dim = self.embedding.embedding_dim\n",
    "        self.emb_fc = nn.Linear(emb_dim, hidden_size)\n",
    "        # self.emb_drop = nn.Dropout(emb_dropout)\n",
    "        self.encoder = StarTransformer(hidden_size=hidden_size,\n",
    "                                       num_layers=num_layers,\n",
    "                                       num_head=num_head,\n",
    "                                       head_dim=head_dim,\n",
    "                                       dropout=dropout,\n",
    "                                       max_len=max_len)\n",
    "        \n",
    "#         conv_block_klass = ConvBlock\n",
    "# #         Embedding Layer\n",
    "#         self.stem = nn.Sequential(\n",
    "#         #             Rearrange('b n d -> b d n'),\n",
    "# #             Dynamic_conv1d(49, 49, 3,padding = 1),\n",
    "#             Residual(conv_block_klass(49)),\n",
    "# #             AttentionPool(49, pool_size = 2)\n",
    "            \n",
    "#         )\n",
    "#         self.stem2 = nn.Sequential(\n",
    "#         #             Rearrange('b n d -> b d n'),\n",
    "#             nn.Conv1d(34, 34, 3,padding = 1),\n",
    "#             Residual(conv_block_klass(34)),\n",
    "#             AttentionPool(34, pool_size = 2)\n",
    "#         )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        r\"\"\"\n",
    "        :param FloatTensor x: [batch, length, hidden] 输入的序列\n",
    "        :param ByteTensor mask: [batch, length] 输入序列的padding mask, 在没有内容(padding 部分) 为 0,\n",
    "            否则为 1\n",
    "        :return: [batch, length, hidden] 编码后的输出序列\n",
    "                [batch, hidden] 全局 relay 节点, 详见论文\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        x = self.emb_fc(x)\n",
    "#         x = self.stem(x)\n",
    "        #nodes, relay, nodes_attns, relays_attns = self.encoder(x3, mask3)\n",
    "        nodes, relay = self.encoder(x, mask)\n",
    "        return nodes, relay, #nodes_attns, relays_attns\n",
    "\n",
    "\n",
    "class _Cls(nn.Module):\n",
    "    def __init__(self, in_dim, num_cls, hid_dim, dropout=0.1):\n",
    "        super(_Cls, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hid_dim, num_cls),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.fc(x)\n",
    "        return h\n",
    "\n",
    "class STSeqCls(nn.Module):\n",
    "    r\"\"\"\n",
    "    用于分类任务的Star-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed, num_cls=2,\n",
    "                 hidden_size=300,\n",
    "                 num_layers=1,\n",
    "                 num_head=9,\n",
    "                 head_dim=32,\n",
    "                 max_len=512,\n",
    "                 cls_hidden_size=600,\n",
    "                 emb_dropout=0.1,\n",
    "                 dropout=0.1):\n",
    "        r\"\"\"\n",
    "        \n",
    "        :param embed: 单词词典, 可以是 tuple, 包括(num_embedings, embedding_dim), 即\n",
    "            embedding的大小和每个词的维度. 也可以传入 nn.Embedding 对象, 此时就以传入的对象作为embedding\n",
    "        :param num_cls: 输出类别个数\n",
    "        :param hidden_size: 模型中特征维度. Default: 300\n",
    "        :param num_layers: 模型层数. Default: 4\n",
    "        :param num_head: 模型中multi-head的head个数. Default: 8\n",
    "        :param head_dim: 模型中multi-head中每个head特征维度. Default: 32\n",
    "        :param max_len: 模型能接受的最大输入长度. Default: 512\n",
    "        :param cls_hidden_size: 分类器隐层维度. Default: 600\n",
    "        :param emb_dropout: 词嵌入的dropout概率. Default: 0.1\n",
    "        :param dropout: 模型除词嵌入外的dropout概率. Default: 0.1\n",
    "        \"\"\"\n",
    "        super(STSeqCls, self).__init__()\n",
    "        self.enc = StarTransEnc(embed=embed,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                num_head=num_head,\n",
    "                                head_dim=head_dim,\n",
    "                                max_len=max_len,\n",
    "                                emb_dropout=emb_dropout,\n",
    "                                dropout=dropout)\n",
    "        self.cls = _Cls(hidden_size, num_cls, cls_hidden_size, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, words, seq_len):\n",
    "        r\"\"\"\n",
    "        :param words: [batch, seq_len] 输入序列\n",
    "        :param seq_len: [batch,] 输入序列的长度\n",
    "        :return output: [batch, num_cls] 输出序列的分类的概率\n",
    "        \"\"\"\n",
    "        mask = seq_len_to_mask(seq_len,max_len=49).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "#         mask2 = seq_len_to_mask(torch.tensor([34]*len(seq_len))).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        nodes, relay = self.enc(words, mask)\n",
    "        y = 0.5 * (relay + nodes.max(1)[0])\n",
    "#         y = torch.cat([relay, torch.sort(nodes,dim=1)[0][:,-1,:], torch.sort(nodes,dim=1)[0][:,-2,:]],1)\n",
    "        \n",
    "        output = self.cls(y)  # [bsz, n_cls]\n",
    "        return output#, nodes_attns, relays_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performances(y_true, y_pred, y_prob, print_ = True):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel().tolist()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    try:\n",
    "        mcc = ((tp*tn) - (fn*fp)) / np.sqrt(np.float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    except:\n",
    "        print('MCC Error: ', (tp+fn)*(tn+fp)*(tp+fp)*(tn+fn))\n",
    "        mcc = np.nan\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    try:\n",
    "        recall = tp / (tp+fn)\n",
    "    except:\n",
    "        recall = np.nan\n",
    "        \n",
    "    try:\n",
    "        precision = tp / (tp+fp)\n",
    "    except:\n",
    "        precision = np.nan\n",
    "        \n",
    "    try: \n",
    "        f1 = 2*precision*recall / (precision+recall)\n",
    "    except:\n",
    "        f1 = np.nan\n",
    "        \n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    prec, reca, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr = auc(reca, prec)\n",
    "    \n",
    "    if print_:\n",
    "        print('tn = {}, fp = {}, fn = {}, tp = {}'.format(tn, fp, fn, tp))\n",
    "        print('y_pred: 0 = {} | 1 = {}'.format(Counter(y_pred)[0], Counter(y_pred)[1]))\n",
    "        print('y_true: 0 = {} | 1 = {}'.format(Counter(y_true)[0], Counter(y_true)[1]))\n",
    "        print('auc={:.4f}|sensitivity={:.4f}|specificity={:.4f}|acc={:.4f}|mcc={:.4f}'.format(roc_auc, sensitivity, specificity, accuracy, mcc))\n",
    "        print('precision={:.4f}|recall={:.4f}|f1={:.4f}|aupr={:.4f}'.format(precision, recall, f1, aupr))\n",
    "    \n",
    "    return (roc_auc, accuracy, mcc, f1, sensitivity, specificity, precision, recall, aupr)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "def transfer(y_prob, threshold = 0.5):\n",
    "    return np.array([[0, 1][x > threshold] for x in y_prob])\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "f_mean = lambda l: sum(l)/len(l)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "def performances_to_pd(performances_list):\n",
    "    metrics_name = ['roc_auc', 'accuracy', 'mcc', 'f1', 'sensitivity', 'specificity', 'precision', 'recall', 'aupr']\n",
    "\n",
    "    performances_pd = pd.DataFrame(performances_list, columns = metrics_name)\n",
    "    performances_pd.loc['mean'] = performances_pd.mean(axis = 0)\n",
    "    performances_pd.loc['std'] = performances_pd.std(axis = 0)\n",
    "    \n",
    "    return performances_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    time_train_ep = 0\n",
    "    model.train()\n",
    "    y_true_train_list, y_prob_train_list = [], []\n",
    "    loss_train_list = []\n",
    "    for train_pep_inputs, train_pep_lens, train_labels in tqdm(train_loader):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        train_outputs: [batch_size, 2]\n",
    "        '''\n",
    "        train_pep_inputs, train_labels = train_pep_inputs.to(device), train_labels.to(device)\n",
    "        train_pep_lens = train_pep_lens.to(device)\n",
    "        t1 = time.time()\n",
    "        train_outputs = model(train_pep_inputs, train_pep_lens)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        time_train_ep += time.time() - t1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true_train = train_labels.cpu().numpy()\n",
    "        y_prob_train = nn.Softmax(dim = 1)(train_outputs)[:, 1].cpu().detach().numpy()\n",
    "        \n",
    "        y_true_train_list.extend(y_true_train)\n",
    "        y_prob_train_list.extend(y_prob_train)\n",
    "        loss_train_list.append(train_loss.item())\n",
    "#         relays_attns_list.append(relays_attns)\n",
    "#         nodes_attns_list.append(nodes_attns)\n",
    "        \n",
    "    y_pred_train_list = transfer(y_prob_train_list, threshold)\n",
    "    ys_train = (y_true_train_list, y_pred_train_list, y_prob_train_list)\n",
    "    \n",
    "    print('Fold-{}****Train (Ep avg): Epoch-{}/{} | Loss = {:.4f} | Time = {:.4f} sec'.format(fold, epoch, epochs, f_mean(loss_train_list), time_train_ep))\n",
    "    metrics_train = performances(y_true_train_list, y_pred_train_list, y_prob_train_list, print_ = True)\n",
    "    \n",
    "    return ys_train, loss_train_list, metrics_train, time_train_ep#, relays_attns_list, nodes_attns_list\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def eval_step(model, val_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    torch.manual_seed(2022)\n",
    "    torch.cuda.manual_seed(2022)\n",
    "    with torch.no_grad():\n",
    "        loss_val_list = []\n",
    "        y_true_val_list, y_prob_val_list = [], []\n",
    "        for val_pep_inputs, val_pep_lens, val_labels in tqdm(val_loader):\n",
    "            val_pep_inputs, val_labels = val_pep_inputs.to(device), val_labels.to(device)\n",
    "            val_pep_lens = val_pep_lens.to(device)\n",
    "            val_outputs = model(val_pep_inputs, val_pep_lens)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            y_true_val = val_labels.cpu().numpy()\n",
    "            y_prob_val = nn.Softmax(dim = 1)(val_outputs)[:, 1].cpu().detach().numpy()\n",
    "\n",
    "            y_true_val_list.extend(y_true_val)\n",
    "            y_prob_val_list.extend(y_prob_val)\n",
    "            loss_val_list.append(val_loss.item())\n",
    "\n",
    "            \n",
    "        y_pred_val_list = transfer(y_prob_val_list, threshold)\n",
    "        ys_val = (y_true_val_list, y_pred_val_list, y_prob_val_list)\n",
    "        \n",
    "        print('Fold-{} ****Test  Epoch-{}/{}: Loss = {:.6f}'.format(fold, epoch, epochs, f_mean(loss_val_list)))\n",
    "        metrics_val = performances(y_true_val_list, y_pred_val_list, y_prob_val_list, print_ = True)\n",
    "    return ys_val, loss_val_list, metrics_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_max_len = 15 # peptide; enc_input max sequence length\n",
    "hla_max_len = 34 # hla; dec_input(=dec_output) max sequence length\n",
    "tgt_len = pep_max_len + hla_max_len\n",
    "pep_max_len, hla_max_len\n",
    "\n",
    "# vocab = np.load('./vocab_dict.npy', allow_pickle = True).item()\n",
    "vocab = {'-': 0,\n",
    " 'Y': 1,\n",
    " 'A': 2,\n",
    " 'T': 3,\n",
    " 'V': 4,\n",
    " 'L': 5,\n",
    " 'D': 6,\n",
    " 'E': 7,\n",
    " 'G': 8,\n",
    " 'R': 9,\n",
    " 'H': 10,\n",
    " 'I': 11,\n",
    " 'W': 12,\n",
    " 'Q': 13,\n",
    " 'K': 14,\n",
    " 'M': 15,\n",
    " 'F': 16,\n",
    " 'N': 17,\n",
    " 'S': 18,\n",
    " 'P': 19,\n",
    " 'C': 20}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "n_layers = 1  # number of Encoder of Decoder Layer\n",
    "n_heads = 8\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 25\n",
    "threshold = 0.5\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G:TransPHLA-AOMP/Dataset/\n",
    "def data_with_loader(type_ = 'train',fold = None,  batch_size = 128):\n",
    "    if type_ != 'train' and type_ != 'val':\n",
    "        data = pd.read_csv('../data/test_set/{}_set.csv'.format(type_), index_col = 0)\n",
    "    elif type_ == 'train':\n",
    "        data = pd.read_csv('../data/train_set/NetMHCpan4.1/train_data_fold{}.csv'.format(fold)) #, index_col = 0\n",
    "    elif type_ == 'val':\n",
    "        data = pd.read_csv('../data/train_set/NetMHCpan4.1/val_data_fold{}.csv'.format(fold)) #, index_col = 0\n",
    "        \n",
    "    pep_inputs, hla_inputs, labels, pep_lens = make_data(data)\n",
    "    loader = Data.DataLoader(MyDataSet(pep_inputs, hla_inputs, pep_lens, labels), batch_size, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    return data, pep_inputs, hla_inputs, pep_lens, labels, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_data, independent_pep_inputs, independent_hla_inputs, independent_pep_lens, independent_labels, independent_loader = data_with_loader(type_ = 'independent',fold = None,  batch_size = batch_size)\n",
    "external_data, external_pep_inputs, external_hla_inputs, external_pep_lens, external_labels, external_loader = data_with_loader(type_ = 'external',fold = None,  batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Fold-0=====\n",
      "-----Generate data loader-----\n",
      "Fold-0 Label info: Train = Counter({1: 277903, 0: 277552}) | Val = Counter({0: 69607, 1: 69256})\n",
      "-----Compile model-----\n",
      "STSeqCls(\n",
      "  (enc): StarTransEnc(\n",
      "    (embedding): Embedding(21, 100, padding_idx=0)\n",
      "    (emb_fc): Linear(in_features=100, out_features=300, bias=True)\n",
      "    (encoder): StarTransformer(\n",
      "      (norm): ModuleList(\n",
      "        (0): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "      (ring_att): ModuleList(\n",
      "        (0): _MSA1(\n",
      "          (WQ): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WK): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WV): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WO): Conv2d(256, 300, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (star_att): ModuleList(\n",
      "        (0): _MSA2(\n",
      "          (WQ): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WK): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WV): Conv2d(300, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (WO): Conv2d(256, 300, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (pos_emb): Embedding(49, 300)\n",
      "    )\n",
      "  )\n",
      "  (cls): _Cls(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=600, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=600, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----Train-----\n",
      "dir_saver:  G:TransPHLA-AOMP/model/STformer/\n",
      "path_saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:53<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-1/25 | Loss = 0.2670 | Time = 5.5459 sec\n",
      "tn = 247570, fp = 29982, fn = 32362, tp = 245541\n",
      "y_pred: 0 = 279932 | 1 = 275523\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9563|sensitivity=0.8835|specificity=0.8920|acc=0.8878|mcc=0.7756\n",
      "precision=0.8912|recall=0.8835|f1=0.8873|aupr=0.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-1/25: Loss = 0.180448\n",
      "tn = 66866, fp = 2741, fn = 6586, tp = 62670\n",
      "y_pred: 0 = 73452 | 1 = 65411\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9804|sensitivity=0.9049|specificity=0.9606|acc=0.9328|mcc=0.8670\n",
      "precision=0.9581|recall=0.9049|f1=0.9307|aupr=0.9819\n",
      "****Saving model: Best epoch = 1 | 5metrics_Best_avg = 0.9277\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:55<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-2/25 | Loss = 0.1679 | Time = 5.5942 sec\n",
      "tn = 262559, fp = 14993, fn = 19681, tp = 258222\n",
      "y_pred: 0 = 282240 | 1 = 273215\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9817|sensitivity=0.9292|specificity=0.9460|acc=0.9376|mcc=0.8753\n",
      "precision=0.9451|recall=0.9292|f1=0.9371|aupr=0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-2/25: Loss = 0.158444\n",
      "tn = 67079, fp = 2528, fn = 5632, tp = 63624\n",
      "y_pred: 0 = 72711 | 1 = 66152\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9843|sensitivity=0.9187|specificity=0.9637|acc=0.9412|mcc=0.8833\n",
      "precision=0.9618|recall=0.9187|f1=0.9397|aupr=0.9855\n",
      "****Saving model: Best epoch = 2 | 5metrics_Best_avg = 0.9372\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-3/25 | Loss = 0.1508 | Time = 5.6924 sec\n",
      "tn = 264445, fp = 13107, fn = 17852, tp = 260051\n",
      "y_pred: 0 = 282297 | 1 = 273158\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9851|sensitivity=0.9358|specificity=0.9528|acc=0.9443|mcc=0.8887\n",
      "precision=0.9520|recall=0.9358|f1=0.9438|aupr=0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-3/25: Loss = 0.146688\n",
      "tn = 66683, fp = 2924, fn = 4572, tp = 64684\n",
      "y_pred: 0 = 71255 | 1 = 67608\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9858|sensitivity=0.9340|specificity=0.9580|acc=0.9460|mcc=0.8923\n",
      "precision=0.9568|recall=0.9340|f1=0.9452|aupr=0.9870\n",
      "****Saving model: Best epoch = 3 | 5metrics_Best_avg = 0.9423\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-4/25 | Loss = 0.1417 | Time = 5.7554 sec\n",
      "tn = 265287, fp = 12265, fn = 16797, tp = 261106\n",
      "y_pred: 0 = 282084 | 1 = 273371\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9868|sensitivity=0.9396|specificity=0.9558|acc=0.9477|mcc=0.8955\n",
      "precision=0.9551|recall=0.9396|f1=0.9473|aupr=0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-4/25: Loss = 0.142897\n",
      "tn = 66144, fp = 3463, fn = 3838, tp = 65418\n",
      "y_pred: 0 = 69982 | 1 = 68881\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9867|sensitivity=0.9446|specificity=0.9502|acc=0.9474|mcc=0.8949\n",
      "precision=0.9497|recall=0.9446|f1=0.9471|aupr=0.9877\n",
      "****Saving model: Best epoch = 4 | 5metrics_Best_avg = 0.9440\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-5/25 | Loss = 0.1342 | Time = 5.6583 sec\n",
      "tn = 266011, fp = 11541, fn = 15956, tp = 261947\n",
      "y_pred: 0 = 281967 | 1 = 273488\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9881|sensitivity=0.9426|specificity=0.9584|acc=0.9505|mcc=0.9011\n",
      "precision=0.9578|recall=0.9426|f1=0.9501|aupr=0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-5/25: Loss = 0.145129\n",
      "tn = 66167, fp = 3440, fn = 4038, tp = 65218\n",
      "y_pred: 0 = 70205 | 1 = 68658\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9864|sensitivity=0.9417|specificity=0.9506|acc=0.9461|mcc=0.8923\n",
      "precision=0.9499|recall=0.9417|f1=0.9458|aupr=0.9874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-6/25 | Loss = 0.1300 | Time = 5.6970 sec\n",
      "tn = 266427, fp = 11125, fn = 15497, tp = 262406\n",
      "y_pred: 0 = 281924 | 1 = 273531\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9889|sensitivity=0.9442|specificity=0.9599|acc=0.9521|mcc=0.9043\n",
      "precision=0.9593|recall=0.9442|f1=0.9517|aupr=0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-6/25: Loss = 0.141861\n",
      "tn = 66732, fp = 2875, fn = 4358, tp = 64898\n",
      "y_pred: 0 = 71090 | 1 = 67773\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9869|sensitivity=0.9371|specificity=0.9587|acc=0.9479|mcc=0.8960\n",
      "precision=0.9576|recall=0.9371|f1=0.9472|aupr=0.9879\n",
      "****Saving model: Best epoch = 6 | 5metrics_Best_avg = 0.9445\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-7/25 | Loss = 0.1253 | Time = 5.6758 sec\n",
      "tn = 266748, fp = 10804, fn = 14950, tp = 262953\n",
      "y_pred: 0 = 281698 | 1 = 273757\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9896|sensitivity=0.9462|specificity=0.9611|acc=0.9536|mcc=0.9074\n",
      "precision=0.9605|recall=0.9462|f1=0.9533|aupr=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-7/25: Loss = 0.140283\n",
      "tn = 66795, fp = 2812, fn = 4286, tp = 64970\n",
      "y_pred: 0 = 71081 | 1 = 67782\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9872|sensitivity=0.9381|specificity=0.9596|acc=0.9489|mcc=0.8980\n",
      "precision=0.9585|recall=0.9381|f1=0.9482|aupr=0.9881\n",
      "****Saving model: Best epoch = 7 | 5metrics_Best_avg = 0.9456\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-8/25 | Loss = 0.1221 | Time = 5.7208 sec\n",
      "tn = 267076, fp = 10476, fn = 14619, tp = 263284\n",
      "y_pred: 0 = 281695 | 1 = 273760\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9902|sensitivity=0.9474|specificity=0.9623|acc=0.9548|mcc=0.9097\n",
      "precision=0.9617|recall=0.9474|f1=0.9545|aupr=0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-8/25: Loss = 0.136898\n",
      "tn = 66494, fp = 3113, fn = 3787, tp = 65469\n",
      "y_pred: 0 = 70281 | 1 = 68582\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9878|sensitivity=0.9453|specificity=0.9553|acc=0.9503|mcc=0.9007\n",
      "precision=0.9546|recall=0.9453|f1=0.9499|aupr=0.9886\n",
      "****Saving model: Best epoch = 8 | 5metrics_Best_avg = 0.9472\n",
      "*****Path saver:  G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer1_multihead8_fold0_netmhcpan.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:57<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-9/25 | Loss = 0.1185 | Time = 5.6671 sec\n",
      "tn = 267306, fp = 10246, fn = 14170, tp = 263733\n",
      "y_pred: 0 = 281476 | 1 = 273979\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9908|sensitivity=0.9490|specificity=0.9631|acc=0.9560|mcc=0.9122\n",
      "precision=0.9626|recall=0.9490|f1=0.9558|aupr=0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:07<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-9/25: Loss = 0.139460\n",
      "tn = 66875, fp = 2732, fn = 4165, tp = 65091\n",
      "y_pred: 0 = 71040 | 1 = 67823\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9877|sensitivity=0.9399|specificity=0.9608|acc=0.9503|mcc=0.9009\n",
      "precision=0.9597|recall=0.9399|f1=0.9497|aupr=0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:56<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-10/25 | Loss = 0.1153 | Time = 5.6505 sec\n",
      "tn = 267537, fp = 10015, fn = 13781, tp = 264122\n",
      "y_pred: 0 = 281318 | 1 = 274137\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9913|sensitivity=0.9504|specificity=0.9639|acc=0.9572|mcc=0.9144\n",
      "precision=0.9635|recall=0.9504|f1=0.9569|aupr=0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-10/25: Loss = 0.143469\n",
      "tn = 66997, fp = 2610, fn = 4394, tp = 64862\n",
      "y_pred: 0 = 71391 | 1 = 67472\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9875|sensitivity=0.9366|specificity=0.9625|acc=0.9496|mcc=0.8994\n",
      "precision=0.9613|recall=0.9366|f1=0.9488|aupr=0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:53<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-11/25 | Loss = 0.1109 | Time = 5.5015 sec\n",
      "tn = 267879, fp = 9673, fn = 13263, tp = 264640\n",
      "y_pred: 0 = 281142 | 1 = 274313\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9919|sensitivity=0.9523|specificity=0.9651|acc=0.9587|mcc=0.9175\n",
      "precision=0.9647|recall=0.9523|f1=0.9585|aupr=0.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-11/25: Loss = 0.142255\n",
      "tn = 67040, fp = 2567, fn = 4350, tp = 64906\n",
      "y_pred: 0 = 71390 | 1 = 67473\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9877|sensitivity=0.9372|specificity=0.9631|acc=0.9502|mcc=0.9007\n",
      "precision=0.9620|recall=0.9372|f1=0.9494|aupr=0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:53<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-12/25 | Loss = 0.1083 | Time = 5.5350 sec\n",
      "tn = 268028, fp = 9524, fn = 12980, tp = 264923\n",
      "y_pred: 0 = 281008 | 1 = 274447\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9923|sensitivity=0.9533|specificity=0.9657|acc=0.9595|mcc=0.9190\n",
      "precision=0.9653|recall=0.9533|f1=0.9593|aupr=0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 19.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-12/25: Loss = 0.144316\n",
      "tn = 66721, fp = 2886, fn = 4058, tp = 65198\n",
      "y_pred: 0 = 70779 | 1 = 68084\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9875|sensitivity=0.9414|specificity=0.9585|acc=0.9500|mcc=0.9001\n",
      "precision=0.9576|recall=0.9414|f1=0.9494|aupr=0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:54<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-13/25 | Loss = 0.1057 | Time = 5.5714 sec\n",
      "tn = 268234, fp = 9318, fn = 12660, tp = 265243\n",
      "y_pred: 0 = 280894 | 1 = 274561\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9927|sensitivity=0.9544|specificity=0.9664|acc=0.9604|mcc=0.9209\n",
      "precision=0.9661|recall=0.9544|f1=0.9602|aupr=0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-13/25: Loss = 0.147516\n",
      "tn = 66550, fp = 3057, fn = 3952, tp = 65304\n",
      "y_pred: 0 = 70502 | 1 = 68361\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9874|sensitivity=0.9429|specificity=0.9561|acc=0.9495|mcc=0.8991\n",
      "precision=0.9553|recall=0.9429|f1=0.9491|aupr=0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:54<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-14/25 | Loss = 0.1034 | Time = 5.5838 sec\n",
      "tn = 268349, fp = 9203, fn = 12456, tp = 265447\n",
      "y_pred: 0 = 280805 | 1 = 274650\n",
      "y_true: 0 = 277552 | 1 = 277903\n",
      "auc=0.9930|sensitivity=0.9552|specificity=0.9668|acc=0.9610|mcc=0.9221\n",
      "precision=0.9665|recall=0.9552|f1=0.9608|aupr=0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:06<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-14/25: Loss = 0.148162\n",
      "tn = 66010, fp = 3597, fn = 3340, tp = 65916\n",
      "y_pred: 0 = 69350 | 1 = 69513\n",
      "y_true: 0 = 69607 | 1 = 69256\n",
      "auc=0.9876|sensitivity=0.9518|specificity=0.9483|acc=0.9500|mcc=0.9001\n",
      "precision=0.9483|recall=0.9518|f1=0.9500|aupr=0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                             | 23/543 [00:02<00:52,  9.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-488a7aca21bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mys_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_train_ep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# , dec_attns_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mys_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, dec_attns_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-19299b785baf>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, train_loader, fold, epoch, epochs, use_cuda)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_true_train_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prob_train_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloss_train_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_pep_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pep_lens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         '''\n\u001b[0;32m     10\u001b[0m         \u001b[0mpep_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpep_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m                     \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlast_print_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmininterval\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmin_start_t\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlast_print_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                         \u001b[0mlast_print_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_print_n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                         \u001b[0mlast_print_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_print_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ema_dn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ema_dt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_miniters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m                     \u001b[1;31m# If no `miniters` was specified, adjust automatically to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1351\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mprint_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m             \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mfp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mfp_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tqdm\\utils.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ys_train_fold_dict, ys_val_fold_dict = {}, {}\n",
    "train_fold_metrics_list, val_fold_metrics_list = [], []\n",
    "independent_fold_metrics_list, external_fold_metrics_list, ys_independent_fold_dict, ys_external_fold_dict = [], [], {}, {}\n",
    "attns_train_fold_dict, attns_val_fold_dict, attns_independent_fold_dict, attns_external_fold_dict = {}, {}, {}, {}\n",
    "loss_train_fold_dict, loss_val_fold_dict, loss_independent_fold_dict, loss_external_fold_dict = {}, {}, {}, {}\n",
    "\n",
    "for fold in range(3,4):\n",
    "    print('=====Fold-{}====='.format(fold))\n",
    "    print('-----Generate data loader-----')\n",
    "    train_data, train_pep_inputs, train_hla_inputs, train_pep_lens, train_labels, train_loader = data_with_loader(type_ = 'train', fold = fold,  batch_size = batch_size)\n",
    "    val_data, val_pep_inputs, val_hla_inputs, val_pep_lens, val_labels, val_loader = data_with_loader(type_ = 'val', fold = fold,  batch_size = batch_size)\n",
    "    print('Fold-{} Label info: Train = {} | Val = {}'.format(fold, Counter(train_data.label), Counter(val_data.label)))\n",
    "\n",
    "    print('-----Compile model-----')\n",
    "    model = STSeqCls((21, 100), num_cls=2, hidden_size=300, num_layers=1, num_head=8, max_len=49,cls_hidden_size=600,dropout=0.1,head_dim=32).to(device)\n",
    "    print(model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)#, momentum = 0.99)\n",
    "#     optimizer = ScheduledOptim(optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09), 2, 64, 10)\n",
    "\n",
    "    print('-----Train-----')\n",
    "    dir_saver = 'G:TransPHLA-AOMP/model/STformer/'\n",
    "    path_saver = 'G:TransPHLA-AOMP/model/STformer/netmhcpan/st_layer{}_multihead{}_fold{}_netmhcpan.pkl'.format(n_layers, n_heads, fold)\n",
    "    print('dir_saver: ', dir_saver)\n",
    "    print('path_saver: ', path_saver)\n",
    "\n",
    "    metric_best, ep_best = 0, -1\n",
    "    time_train = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        ys_train, loss_train_list, metrics_train, time_train_ep = train_step(model, train_loader, fold, epoch, epochs, use_cuda) # , dec_attns_train\n",
    "        ys_val, loss_val_list, metrics_val = eval_step(model, val_loader, fold, epoch, epochs, use_cuda) #, dec_attns_val\n",
    "\n",
    "        metrics_ep_avg = sum(metrics_val[:4])/4\n",
    "        if metrics_ep_avg > metric_best: \n",
    "            metric_best, ep_best = metrics_ep_avg, epoch\n",
    "            if not os.path.exists(dir_saver):\n",
    "                os.makedirs(dir_saver)\n",
    "            print('****Saving model: Best epoch = {} | 5metrics_Best_avg = {:.4f}'.format(ep_best, metric_best))\n",
    "            print('*****Path saver: ', path_saver)\n",
    "            torch.save(model.eval().state_dict(), path_saver)\n",
    "\n",
    "        time_train += time_train_ep\n",
    "\n",
    "    print('-----Optimization Finished!-----')\n",
    "    print('-----Evaluate Results-----')\n",
    "    if ep_best >= 0:\n",
    "        print('*****Path saver: ', path_saver)\n",
    "        model.load_state_dict(torch.load(path_saver))\n",
    "        model_eval = model.eval()\n",
    "\n",
    "        ys_res_train, loss_res_train_list, metrics_res_train = eval_step(model_eval, train_loader, fold, ep_best, epochs, use_cuda) # , train_res_attns\n",
    "        ys_res_val, loss_res_val_list, metrics_res_val = eval_step(model_eval, val_loader, fold, ep_best, epochs, use_cuda) # , val_res_attns\n",
    "        ys_res_independent, loss_res_independent_list, metrics_res_independent = eval_step(model_eval, independent_loader, fold, ep_best, epochs, use_cuda) # , independent_res_attns\n",
    "        ys_res_external, loss_res_external_list, metrics_res_external = eval_step(model_eval, external_loader, fold, ep_best, epochs, use_cuda) # , external_res_attns\n",
    "\n",
    "        train_fold_metrics_list.append(metrics_res_train)\n",
    "        val_fold_metrics_list.append(metrics_res_val)\n",
    "        independent_fold_metrics_list.append(metrics_res_independent)\n",
    "        external_fold_metrics_list.append(metrics_res_external)\n",
    "\n",
    "        ys_train_fold_dict[fold], ys_val_fold_dict[fold], ys_independent_fold_dict[fold], ys_external_fold_dict[fold] = ys_res_train, ys_res_val, ys_res_independent, ys_res_external    \n",
    "        loss_train_fold_dict[fold], loss_val_fold_dict[fold], loss_independent_fold_dict[fold], loss_external_fold_dict[fold] = loss_res_train_list, loss_res_val_list, loss_res_independent_list, loss_res_external_list  \n",
    "\n",
    "    print(\"Total training time: {:6.2f} sec\".format(time_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_saver = '../model/st_layer1_multihead8_fold3_netmhcpan.pkl'\n",
    "model = STSeqCls((21, 100), num_cls=2, hidden_size=300, num_layers=1, num_head=8, max_len=49,cls_hidden_size=600,dropout=0.1,head_dim=32).to(device)\n",
    "model.load_state_dict(torch.load(path_saver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 168/168 [00:08<00:00, 19.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-3 ****Test  Epoch-7/25: Loss = 0.367765\n",
      "tn = 74424, fp = 11138, fn = 9313, tp = 76563\n",
      "y_pred: 0 = 83737 | 1 = 87701\n",
      "y_true: 0 = 85562 | 1 = 85876\n",
      "auc=0.9444|sensitivity=0.8916|specificity=0.8698|acc=0.8807|mcc=0.7616\n",
      "precision=0.8730|recall=0.8916|f1=0.8822|aupr=0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 102/102 [00:05<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-3 ****Test  Epoch-7/25: Loss = 0.336248\n",
      "tn = 46839, fp = 5042, fn = 7528, tp = 44456\n",
      "y_pred: 0 = 54367 | 1 = 49498\n",
      "y_true: 0 = 51881 | 1 = 51984\n",
      "auc=0.9410|sensitivity=0.8552|specificity=0.9028|acc=0.8790|mcc=0.7588\n",
      "precision=0.8981|recall=0.8552|f1=0.8761|aupr=0.9472\n"
     ]
    }
   ],
   "source": [
    "# model = model_eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fold = 3\n",
    "ep_best = 7\n",
    "\n",
    "model_eval = model.eval()\n",
    "ys_res_independent, loss_res_independent_list, metrics_res_independent = eval_step(model_eval, independent_loader, fold, ep_best, epochs, use_cuda) # , independent_res_attns\n",
    "ys_res_external, loss_res_external_list, metrics_res_external = eval_step(model_eval, external_loader, fold, ep_best, epochs, use_cuda) # , external_res_attns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
